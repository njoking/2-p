{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9WtnBkHpVKFnrTydh4zq3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njoking/2-p/blob/main/Sales_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qL-qS4NbQEpV",
        "outputId": "b6335d3b-8554-4414-ebf7-1d6a4958d7f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed61d1e7-c6fe-4f66-8d69-147487baa3f1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ed61d1e7-c6fe-4f66-8d69-147487baa3f1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Consumer Insights Specialist Case Study.xlsx to Consumer Insights Specialist Case Study.xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Python or R, please conduct the following analysis. Attach code in your final output"
      ],
      "metadata": {
        "id": "WtskEbPMQcyn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MWzvTh18QidM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. Top 5 best-selling items (based on volumes).\n",
        "\n"
      ],
      "metadata": {
        "id": "QeMDJsxMQjfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = 'Consumer Insights Specialist Case Study.xlsx'\n",
        "\n",
        "# List all sheet names to identify the correct sheet for Task 2\n",
        "sheet_names = pd.ExcelFile(file_path).sheet_names\n",
        "print(\"Available Sheets:\", sheet_names)\n",
        "\n",
        "# Load the sheet corresponding to Task 2 (adjust sheet name if necessary)\n",
        "# Replace 'Task 2 Data' with the actual sheet name if it is different\n",
        "df_task2 = pd.read_excel(file_path, sheet_name='Task 2 Data')\n",
        "\n",
        "# Clean the column names by removing extra spaces and converting to lowercase\n",
        "df_task2.columns = df_task2.columns.str.strip().str.lower()\n",
        "\n",
        "# Check the columns to verify they match the expected ones ('itemname' and 'qty')\n",
        "print(\"Columns in Task 2:\", df_task2.columns)\n",
        "\n",
        "# Group by 'itemname' and sum the quantity ('qty') for each item\n",
        "top_items = df_task2.groupby('itemname')['qty'].sum().reset_index()\n",
        "\n",
        "# Sort the items by quantity in descending order and select the top 5 best-sellers\n",
        "top_5_best_sellers = top_items.sort_values(by='qty', ascending=False).head(5)\n",
        "\n",
        "# Display the top 5 best-selling items\n",
        "print(\"Top 5 Best-Selling Items:\")\n",
        "print(top_5_best_sellers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MptDi1wfRGIH",
        "outputId": "ec42bad4-2117-45b4-8d94-ef584fb11e1f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Sheets: ['Test Instructions', 'Task 1 Data', 'Task 2 Data']\n",
            "Columns in Task 2: Index(['transdate', 'receiptid', 'itemname', 'department', 'category',\n",
            "       'fineline', 'brand', 'qty', 'netamountincltax', 'price', 'customeracc',\n",
            "       'gender', 'age'],\n",
            "      dtype='object')\n",
            "Top 5 Best-Selling Items:\n",
            "                           itemname    qty\n",
            "522   MT.KENYA UHT MILK 500ML POUCH  264.0\n",
            "89   BROOKSIDE DAIRYBEST MILK 500ML   51.0\n",
            "609               PASCHA FINO 500ML   43.0\n",
            "718             SOKO MAIZE MEAL 2KG   30.0\n",
            "391  KASUKU SUP EX BOOK A4 120P S/L   28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Oh5aDLodV87b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Top 3 brands contributing the highest revenue."
      ],
      "metadata": {
        "id": "DFi-PYBVUFSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = 'Consumer Insights Specialist Case Study.xlsx'\n",
        "\n",
        "# List all sheet names to identify the correct sheet for Task 2\n",
        "sheet_names = pd.ExcelFile(file_path).sheet_names\n",
        "print(\"Available Sheets:\", sheet_names)\n",
        "\n",
        "# Load the sheet corresponding to Task 2 (adjust sheet name if necessary)\n",
        "df_task2 = pd.read_excel(file_path, sheet_name='Task 2 Data')\n",
        "\n",
        "# Clean the column names by removing extra spaces and converting to lowercase\n",
        "df_task2.columns = df_task2.columns.str.strip().str.lower()\n",
        "\n",
        "# Check the columns to verify they match the expected ones ('brand', 'qty', 'price')\n",
        "print(\"Columns in Task 2:\", df_task2.columns)\n",
        "\n",
        "# Calculate the revenue for each row (qty * price)\n",
        "df_task2['revenue'] = df_task2['qty'] * df_task2['price']\n",
        "\n",
        "# Group by 'brand' and sum the revenue for each brand\n",
        "top_brands = df_task2.groupby('brand')['revenue'].sum().reset_index()\n",
        "\n",
        "# Sort the brands by revenue in descending order and select the top 3\n",
        "top_3_brands = top_brands.sort_values(by='revenue', ascending=False).head(3)\n",
        "\n",
        "# Display the top 3 brands contributing the highest revenue\n",
        "print(\"Top 3 Brands Contributing the Highest Revenue:\")\n",
        "print(top_3_brands)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N3CNGyZUJUa",
        "outputId": "0c39b927-093f-4533-980b-4f44ba86e8ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Sheets: ['Test Instructions', 'Task 1 Data', 'Task 2 Data']\n",
            "Columns in Task 2: Index(['transdate', 'receiptid', 'itemname', 'department', 'category',\n",
            "       'fineline', 'brand', 'qty', 'netamountincltax', 'price', 'customeracc',\n",
            "       'gender', 'age'],\n",
            "      dtype='object')\n",
            "Top 3 Brands Contributing the Highest Revenue:\n",
            "        brand       revenue\n",
            "104     FRESH  12035.000001\n",
            "209  MT.KENYA  10785.000000\n",
            "121     HAIER   9795.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Day of the week with the highest sales volume."
      ],
      "metadata": {
        "id": "LRN76qVJUTzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = 'Consumer Insights Specialist Case Study.xlsx'\n",
        "\n",
        "# Load the sheet corresponding to Task 2 (adjust sheet name if necessary)\n",
        "df_task2 = pd.read_excel(file_path, sheet_name='Task 2 Data')\n",
        "\n",
        "# Clean the column names by removing extra spaces and converting to lowercase\n",
        "df_task2.columns = df_task2.columns.str.strip().str.lower()\n",
        "\n",
        "# Convert the 'transdate' column to datetime\n",
        "df_task2['transdate'] = pd.to_datetime(df_task2['transdate'], errors='coerce')\n",
        "\n",
        "# Extract the day of the week from the 'transdate' column (0 = Monday, 6 = Sunday)\n",
        "df_task2['day_of_week'] = df_task2['transdate'].dt.day_name()\n",
        "\n",
        "# Group by 'day_of_week' and sum the quantity ('qty') for each day\n",
        "day_sales = df_task2.groupby('day_of_week')['qty'].sum().reset_index()\n",
        "\n",
        "# Sort the days by quantity in descending order and find the day with the highest sales volume\n",
        "day_sales_sorted = day_sales.sort_values(by='qty', ascending=False)\n",
        "\n",
        "# Display the day of the week with the highest sales volume\n",
        "print(\"Day of the Week with the Highest Sales Volume:\")\n",
        "print(day_sales_sorted.head(1))  # Display the top day\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_DRCSCyUpri",
        "outputId": "8530f0f3-0058-4b4c-a80f-d21c5508f93e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Day of the Week with the Highest Sales Volume:\n",
            "  day_of_week         qty\n",
            "3      Sunday  1478.56996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Gender-wise and age-wise distribution of customers."
      ],
      "metadata": {
        "id": "bTXd2_UuV_JF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File path (already uploaded in your Colab environment)\n",
        "file_path = 'Consumer Insights Specialist Case Study.xlsx'\n",
        "\n",
        "# Load the \"Task 2 Data\" sheet\n",
        "df = pd.read_excel(file_path, sheet_name='Task 2 Data')\n",
        "\n",
        "# Clean the column names\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Ensure relevant columns are available\n",
        "required_columns = ['gender', 'age', 'customeracc']\n",
        "df = df[required_columns]\n",
        "\n",
        "# Handle missing or invalid data in the relevant columns\n",
        "df = df.dropna(subset=required_columns)\n",
        "\n",
        "# Ensure unique customers for accurate distribution\n",
        "df = df.drop_duplicates(subset=['customeracc'])\n",
        "\n",
        "# Group by gender and age, counting the number of unique customers in each group\n",
        "customer_distribution = df.groupby(['gender', 'age'])['customeracc'].nunique().reset_index()\n",
        "\n",
        "# Rename columns for clarity\n",
        "customer_distribution.columns = ['gender', 'age', 'customer_count']\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nGender-wise and Age-wise Distribution of Customers:\")\n",
        "print(customer_distribution)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVviqQDMWOD2",
        "outputId": "e18ab98b-af08-4d1f-a3e6-f4dd66580b75"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gender-wise and Age-wise Distribution of Customers:\n",
            "   gender     age  customer_count\n",
            "0       F  18 -28              31\n",
            "1       F  29 -39              25\n",
            "2       F  40 -50              26\n",
            "3       F  51 -61               2\n",
            "4       F  62 -72               1\n",
            "5       M  18 -28              16\n",
            "6       M  29 -39              27\n",
            "7       M  40 -50              12\n",
            "8       M  51 -61               4\n",
            "9       M  62 -72               2\n",
            "10      M  73 -83               1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Identify the most popular category among each gender and age group."
      ],
      "metadata": {
        "id": "bG2mZIlSXxMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "\n",
        "# File path (already uploaded in your Colab environment)\n",
        "file_path = 'Consumer Insights Specialist Case Study.xlsx'\n",
        "\n",
        "# Load the \"Task 2 Data\" sheet\n",
        "df = pd.read_excel(file_path, sheet_name='Task 2 Data')\n",
        "\n",
        "# Clean the column names\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Ensure relevant columns are available\n",
        "required_columns = ['gender', 'age', 'category', 'qty']\n",
        "df = df[required_columns]\n",
        "\n",
        "# Handle missing or invalid data in the relevant columns\n",
        "df = df.dropna(subset=required_columns)\n",
        "\n",
        "# Group by gender, age, and category, summing the quantities for each group\n",
        "category_popularity = df.groupby(['gender', 'age', 'category'])['qty'].sum().reset_index()\n",
        "\n",
        "# Find the most popular category for each gender and age group\n",
        "most_popular_category = category_popularity.loc[\n",
        "    category_popularity.groupby(['gender', 'age'])['qty'].idxmax()\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nMost Popular Category by Gender and Age Group:\")\n",
        "print(most_popular_category)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iMLV-beX0Hi",
        "outputId": "492a4bda-a3fa-4b3b-bbf6-c0941d82f295"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Most Popular Category by Gender and Age Group:\n",
            "   gender     age              category   qty\n",
            "0       F  18 -28         LONGLIFE MILK  95.0\n",
            "1       F  29 -39         LONGLIFE MILK  56.0\n",
            "2       F  40 -50     SCHOOL STATIONERY  93.0\n",
            "3       F  51 -61        BABY SKIN CARE   1.0\n",
            "4       F  62 -72         LONGLIFE MILK  30.0\n",
            "5       M  18 -28           WHEAT FLOUR  42.0\n",
            "6       M  29 -39         LONGLIFE MILK  91.0\n",
            "7       M  40 -50     SCHOOL STATIONERY  18.0\n",
            "8       M  51 -61           MAIZE FLOUR  20.0\n",
            "9       M  62 -72            FRESH MILK  10.0\n",
            "10      M  73 -83  ALL PURPOSE CLEANERS   2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Average Basket Value"
      ],
      "metadata": {
        "id": "OXMcDhECZu3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yxOBGMCeZ131"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File path (already uploaded in your Colab environment)\n",
        "file_path = 'Consumer Insights Specialist Case Study.xlsx'\n",
        "\n",
        "# Load the \"Task 2 Data\" sheet\n",
        "df = pd.read_excel(file_path, sheet_name='Task 2 Data')\n",
        "\n",
        "# Clean the column names\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Ensure relevant columns are available\n",
        "required_columns = ['customeracc', 'gender', 'age', 'qty', 'price', 'receiptid']\n",
        "df = df[required_columns]\n",
        "\n",
        "# Handle missing or invalid data in the relevant columns\n",
        "df = df.dropna(subset=required_columns)\n",
        "\n",
        "# Calculate revenue per transaction (qty * price)\n",
        "df['revenue'] = df['qty'] * df['price']\n",
        "\n",
        "# Group by customer to calculate total revenue and count of transactions (receipts)\n",
        "customer_revenue = df.groupby('customeracc').agg(\n",
        "    total_revenue=('revenue', 'sum'),\n",
        "    transaction_count=('receiptid', 'nunique'),\n",
        "    gender=('gender', 'first'),\n",
        "    age=('age', 'first')\n",
        ").reset_index()\n",
        "\n",
        "# Calculate the Average Basket Value (ABV) per customer\n",
        "customer_revenue['avg_basket_value'] = customer_revenue['total_revenue'] / customer_revenue['transaction_count']\n",
        "\n",
        "# Group by gender and age to find patterns in ABV\n",
        "abv_by_gender_age = customer_revenue.groupby(['gender', 'age']).agg(\n",
        "    avg_abv=('avg_basket_value', 'mean'),\n",
        "    customer_count=('customeracc', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nAverage Basket Value by Gender and Age:\")\n",
        "print(abv_by_gender_age)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJhMAk7qZ2Xj",
        "outputId": "2541299f-2cf8-462f-e872-355a65b5fd1a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Basket Value by Gender and Age:\n",
            "   gender     age      avg_abv  customer_count\n",
            "0       F  18 -28  1834.596772              31\n",
            "1       F  29 -39  1276.300012              25\n",
            "2       F  40 -50  2215.730763              26\n",
            "3       F  51 -61  1069.500000               2\n",
            "4       F  62 -72  5463.000000               1\n",
            "5       M  18 -28  1601.531254              16\n",
            "6       M  29 -39  3049.777778              27\n",
            "7       M  40 -50  1533.791667              12\n",
            "8       M  51 -61  7130.125000               4\n",
            "9       M  62 -72  1436.000001               2\n",
            "10      M  73 -83  2463.000000               1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Identify customer segments that generate the highest revenue (e.g., age group, gender, or category preference).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oj3fya08bo2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming the file has already been uploaded in the current Colab session\n",
        "# Load the Excel file into a DataFrame (Targeting the \"Task 2 Data\" sheet)\n",
        "file_path = '/content/Consumer Insights Specialist Case Study.xlsx'  # Path to the uploaded file\n",
        "df = pd.read_excel(file_path, sheet_name='Task 2 Data')  # Load data from 'Task 2 Data' sheet\n",
        "\n",
        "# Standardize column names for consistency\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Display initial rows and column info to verify the data\n",
        "print(\"Initial Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Select relevant columns\n",
        "required_columns = ['customeracc', 'gender', 'age', 'category', 'qty', 'price']\n",
        "df = df[required_columns]\n",
        "\n",
        "# Clean 'age' column to handle both formats: '18 - 28' and '18-28'\n",
        "df['age'] = df['age'].str.replace(' ', '', regex=True)  # Remove spaces if any\n",
        "\n",
        "# Now split by ' - ' and extract the lower bound, then convert to float\n",
        "df['age'] = df['age'].str.split('-').str[0].astype(float)\n",
        "\n",
        "# Remove rows with missing or invalid data\n",
        "df = df.dropna(subset=['customeracc', 'gender', 'age', 'category', 'qty', 'price'])\n",
        "\n",
        "# Ensure 'qty' and 'price' are positive\n",
        "df = df[(df['qty'] > 0) & (df['price'] > 0)]\n",
        "\n",
        "# Display after cleaning data\n",
        "print(\"\\nFiltered Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows of the filtered dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Calculate revenue for each transaction\n",
        "df['revenue'] = df['qty'] * df['price']\n",
        "\n",
        "# Define age groups\n",
        "age_bins = [0, 18, 25, 35, 45, 55, 65, 100]\n",
        "age_labels = ['0-18', '19-25', '26-35', '36-45', '46-55', '56-65', '65+']\n",
        "df['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, right=False)\n",
        "\n",
        "# Group by gender, age group, and category to calculate total revenue\n",
        "segment_revenue = df.groupby(['gender', 'age_group', 'category']).agg(\n",
        "    total_revenue=('revenue', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Display segment revenue to ensure it's populated correctly\n",
        "print(\"\\nSegment Revenue Data:\")\n",
        "print(segment_revenue)\n",
        "\n",
        "# Identify the segment generating the highest revenue within each gender and age group\n",
        "highest_revenue_segments = segment_revenue.loc[\n",
        "    segment_revenue.groupby(['gender', 'age_group'])['total_revenue'].idxmax()\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nCustomer Segments Generating the Highest Revenue:\")\n",
        "print(highest_revenue_segments)\n",
        "\n",
        "# Save the results to a CSV file\n",
        "highest_revenue_segments.to_csv('highest_revenue_segments.csv', index=False)\n",
        "print(\"\\nResults saved as 'highest_revenue_segments.csv'. You can download it from the files section.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq2ihq86b6cM",
        "outputId": "d3853d77-41bb-43ba-f31f-43282376b301"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1515 entries, 0 to 1514\n",
            "Data columns (total 13 columns):\n",
            " #   Column            Non-Null Count  Dtype         \n",
            "---  ------            --------------  -----         \n",
            " 0   transdate         1515 non-null   datetime64[ns]\n",
            " 1   receiptid         1515 non-null   object        \n",
            " 2   itemname          1515 non-null   object        \n",
            " 3   department        1515 non-null   object        \n",
            " 4   category          1515 non-null   object        \n",
            " 5   fineline          1515 non-null   object        \n",
            " 6   brand             1515 non-null   object        \n",
            " 7   qty               1515 non-null   float64       \n",
            " 8   netamountincltax  1515 non-null   float64       \n",
            " 9   price             1515 non-null   int64         \n",
            " 10  customeracc       1515 non-null   object        \n",
            " 11  gender            1515 non-null   object        \n",
            " 12  age               1515 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(2), int64(1), object(9)\n",
            "memory usage: 154.0+ KB\n",
            "None\n",
            "\n",
            "First few rows of the dataset:\n",
            "   transdate  receiptid                    itemname          department  \\\n",
            "0 2008-07-27  298-01142         SOKO MAIZE MEAL 5KG               FLOUR   \n",
            "1 2008-07-27  298-01204  BELLA WHITE T/PAPER 10PACK    PAPER + PLASTICS   \n",
            "2 2008-07-26  298-01015  BELLA WHITE T/PAPER 4 PACK    PAPER + PLASTICS   \n",
            "3 2008-07-27  298-01269             KENPOLY MUG 330  KITCHEN AND DINING   \n",
            "4 2008-07-21  298-00091  BELLA WHITE T/PAPER 4 PACK    PAPER + PLASTICS   \n",
            "\n",
            "        category              fineline    brand  qty  netamountincltax  price  \\\n",
            "0    MAIZE FLOUR  STANDARD MAIZE FLOUR     SOKO  1.0             253.0    253   \n",
            "1  TISSUE PAPERS               BLENDED    BELLA  1.0             199.0    199   \n",
            "2  TISSUE PAPERS               BLENDED    BELLA  3.0             207.0     69   \n",
            "3     TABLEWARES            DRINKWARES  KENPOLY  1.0              32.0     32   \n",
            "4  TISSUE PAPERS               BLENDED    BELLA  2.0             138.0     69   \n",
            "\n",
            "  customeracc gender     age  \n",
            "0   CD-966516      F  18 -28  \n",
            "1   CD-169085      F  29 -39  \n",
            "2   CD-822352      F  40 -50  \n",
            "3   CD-207673      F  40 -50  \n",
            "4   CD-936825      M  29 -39  \n",
            "\n",
            "Filtered Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1515 entries, 0 to 1514\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   customeracc  1515 non-null   object \n",
            " 1   gender       1515 non-null   object \n",
            " 2   age          1515 non-null   float64\n",
            " 3   category     1515 non-null   object \n",
            " 4   qty          1515 non-null   float64\n",
            " 5   price        1515 non-null   int64  \n",
            "dtypes: float64(2), int64(1), object(3)\n",
            "memory usage: 71.1+ KB\n",
            "None\n",
            "\n",
            "First few rows of the filtered dataset:\n",
            "  customeracc gender   age       category  qty  price\n",
            "0   CD-966516      F  18.0    MAIZE FLOUR  1.0    253\n",
            "1   CD-169085      F  29.0  TISSUE PAPERS  1.0    199\n",
            "2   CD-822352      F  40.0  TISSUE PAPERS  3.0     69\n",
            "3   CD-207673      F  40.0     TABLEWARES  1.0     32\n",
            "4   CD-936825      M  29.0  TISSUE PAPERS  2.0     69\n",
            "\n",
            "Segment Revenue Data:\n",
            "     gender age_group              category  total_revenue\n",
            "0         F      0-18              AEROSOLS            0.0\n",
            "1         F      0-18  ALL PURPOSE CLEANERS            0.0\n",
            "2         F      0-18    ANTISEPTIC LIQUIDS            0.0\n",
            "3         F      0-18         AROMATIC RICE            0.0\n",
            "4         F      0-18          BABY HYGIENE            0.0\n",
            "...     ...       ...                   ...            ...\n",
            "1871      M       65+                 WATER            0.0\n",
            "1872      M       65+           WHEAT FLOUR          138.0\n",
            "1873      M       65+           WHITE SUGAR           99.0\n",
            "1874      M       65+                  WINE            0.0\n",
            "1875      M       65+               YOGHURT            0.0\n",
            "\n",
            "[1876 rows x 4 columns]\n",
            "\n",
            "Customer Segments Generating the Highest Revenue:\n",
            "   gender age_group              category  total_revenue\n",
            "0       F      0-18              AEROSOLS       0.000000\n",
            "1       F     19-25         VEGETABLE OIL    4546.000000\n",
            "2       F     26-35          BABY HYGIENE    3404.000000\n",
            "3       F     36-45     SCHOOL STATIONERY    3247.000000\n",
            "4       F     46-55             OLIVE OIL     495.000000\n",
            "5       F     56-65         VEGETABLE OIL    2449.000000\n",
            "6       F       65+              AEROSOLS       0.000000\n",
            "7       M      0-18              AEROSOLS       0.000000\n",
            "8       M     19-25           WHEAT FLOUR    5161.000000\n",
            "9       M     26-35            DETERGENTS    7966.000000\n",
            "10      M     36-45                 JUICE    1860.000000\n",
            "11      M     46-55             MICROWAVE    9795.000000\n",
            "12      M     56-65                FRUITS     530.000002\n",
            "13      M       65+  TOILET + SEPTIC CARE     480.000000\n",
            "\n",
            "Results saved as 'highest_revenue_segments.csv'. You can download it from the files section.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-98a8fa55dba5>:49: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  segment_revenue = df.groupby(['gender', 'age_group', 'category']).agg(\n",
            "<ipython-input-42-98a8fa55dba5>:59: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  segment_revenue.groupby(['gender', 'age_group'])['total_revenue'].idxmax()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the findings, provide 2-3 recommendations for the marketing or sales teams to improve performance.\n",
        "\n",
        "\n",
        "\n",
        "1.   Target High-Revenue Age Groups\n",
        "2.   Promote Popular Categories for Specific Genders\n",
        "3.   Focus on High-Value Product Categories for\n",
        "     Revenue Growth\n",
        "\n"
      ],
      "metadata": {
        "id": "pOPSvXUzkyqC"
      }
    }
  ]
}